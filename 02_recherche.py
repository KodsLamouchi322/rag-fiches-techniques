"""
=============================================================
  MODULE 2 : RECHERCHE SÃ‰MANTIQUE (RAG)
  âœ… VERSION SANS PGVECTOR
  
  Fonctionnement :
  1. ReÃ§oit une question utilisateur
  2. GÃ©nÃ¨re l'embedding de la question (all-MiniLM-L6-v2)
  3. RÃ©cupÃ¨re tous les vecteurs depuis PostgreSQL
  4. Calcule la similaritÃ© cosinus en Python (sklearn)
  5. Retourne les Top K=3 fragments les plus pertinents
=============================================================
"""

import os
import json
import psycopg2
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_NAME = "all-MiniLM-L6-v2"
TOP_K = 3

DB_CONFIG = {
    "host":     os.getenv("DB_HOST", "localhost"),
    "port":     os.getenv("DB_PORT", "5432"),
    "dbname":   os.getenv("DB_NAME", "enzymes_db"),
    "user":     os.getenv("DB_USER", "postgres"),
    "password": os.getenv("DB_PASSWORD", ""),
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FONCTIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def connecter_bd():
    return psycopg2.connect(**DB_CONFIG)


def recuperer_tous_les_embeddings(conn):
    """
    RÃ©cupÃ¨re tous les fragments et leurs vecteurs depuis la base.
    Les vecteurs sont stockÃ©s en JSON â†’ on les reparse en numpy.
    """
    sql = "SELECT id, texte_fragment, vecteur FROM embeddings;"

    with conn.cursor() as cur:
        cur.execute(sql)
        rows = cur.fetchall()

    if not rows:
        return [], [], np.array([])

    ids, fragments, vecteurs = [], [], []

    for row in rows:
        id_, texte, vecteur_json = row
        ids.append(id_)
        fragments.append(texte)
        # Convertir le JSON string "[0.1, 0.2, ...]" en liste Python
        vecteur_liste = json.loads(vecteur_json)
        vecteurs.append(vecteur_liste)

    matrice_vect = np.array(vecteurs, dtype=np.float32)
    return ids, fragments, matrice_vect


def recherche_semantique(question: str, modele: SentenceTransformer, conn) -> list[dict]:
    """
    CÅ“ur du module RAG :
    1. Encode la question
    2. Compare avec tous les fragments (cosine similarity)
    3. Retourne le Top K
    """
    # Ã‰TAPE 1 : GÃ©nÃ©rer l'embedding de la question
    embedding_question = modele.encode(
        [question],
        normalize_embeddings=True
    )  # shape: (1, 384)

    # Ã‰TAPE 2 : RÃ©cupÃ©rer tous les fragments
    ids, fragments, matrice_vect = recuperer_tous_les_embeddings(conn)

    if len(fragments) == 0:
        print("âš  La base est vide ! Lancez d'abord 01_ingestion.py")
        return []

    # Ã‰TAPE 3 : SimilaritÃ© cosinus
    scores = cosine_similarity(embedding_question, matrice_vect)[0]

    # Ã‰TAPE 4 : Trier par score dÃ©croissant â†’ Top K
    indices_tries = np.argsort(scores)[::-1][:TOP_K]

    # Ã‰TAPE 5 : Construire les rÃ©sultats
    resultats = []
    for rang, idx in enumerate(indices_tries, start=1):
        resultats.append({
            "rang":  rang,
            "texte": fragments[idx],
            "score": float(scores[idx]),
            "id":    ids[idx],
        })

    return resultats


def afficher_resultats(resultats: list[dict], question: str):
    """Affiche les rÃ©sultats de maniÃ¨re claire."""
    print("\n" + "â•" * 70)
    print(f"  ğŸ” QUESTION : {question}")
    print("â•" * 70)

    if not resultats:
        print("  Aucun rÃ©sultat trouvÃ©.")
        return

    for res in resultats:
        print(f"\n  ğŸ“Œ RÃ©sultat {res['rang']}")
        print(f"  {'â”€' * 66}")
        print(f"  ğŸ“„ Texte :")
        texte = res['texte']
        for i in range(0, len(texte), 80):
            print(f"     {texte[i:i+80]}")
        print(f"\n  ğŸ¯ Score de similaritÃ© : {res['score']:.4f}")

    print("\n" + "â•" * 70)


def main():
    print("=" * 70)
    print("  MODULE DE RECHERCHE SÃ‰MANTIQUE - RAG (Boulangerie & PÃ¢tisserie)")
    print("=" * 70)

    # 1. Charger le modÃ¨le
    print(f"\nğŸ“¦ Chargement du modÃ¨le '{MODEL_NAME}'...")
    modele = SentenceTransformer(MODEL_NAME)
    print("âœ… ModÃ¨le prÃªt.")

    # 2. Connexion BD
    print("\nğŸ”Œ Connexion Ã  PostgreSQL...")
    try:
        conn = connecter_bd()
        print("âœ… Connexion Ã©tablie.")
    except Exception as e:
        print(f"âŒ Erreur de connexion : {e}")
        print("ğŸ‘‰ VÃ©rifiez votre fichier .env")
        return

    # 3. Boucle interactive
    print("\nğŸ’¡ Entrez vos questions (tapez 'quitter' pour arrÃªter)\n")

    while True:
        question = input("â“ Votre question : ").strip()

        if question.lower() in ["quitter", "quit", "exit", "q"]:
            print("\nğŸ‘‹ Au revoir !")
            break

        if not question:
            print("  âš  Question vide.\n")
            continue

        resultats = recherche_semantique(question, modele, conn)
        afficher_resultats(resultats, question)
        print()

    conn.close()


if __name__ == "__main__":
    main()
